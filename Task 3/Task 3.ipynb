{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa85839b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import os.path\n",
    "\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aea5632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image loader helper function\n",
    "def default_image_loader(path):\n",
    "    return Image.open(path).convert('RGB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd6fd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "im = Image.open(r\"C:\\Users\\xiaow\\OneDrive\\Desktop\\Spring 2022\\Introduction to Machine Learning\\Introduction-to-Machine-Learning\\Task 3\\food\\00001.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb865c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9407678a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.asarray(im)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7960455c",
   "metadata": {},
   "outputs": [],
   "source": [
    "im.resize((354,242))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fe9cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletImageLoader(torch.utils.data.Dataset):\n",
    "    def __init__(self, base_path, triplets_file_name, transform=None, loader=default_image_loader):\n",
    "        \"\"\" base_path: The path contains the text file of the training triplets\n",
    "            triplets_file_name: The text file with each line containing three integers, \n",
    "            where integer i refers to the i-th image in the filenames file.  \n",
    "            Each line contains three integers (a triplet).\n",
    "            For example, the triplet \"00723 00478 02630\" denotes that the dish in image \"00723.jpg\" is more similar in taste \n",
    "            to the dish in image \"00478.jpg\" than to the dish in image \"02630.jpg\" according to a human annotator.\n",
    "         \"\"\"\n",
    "        self.base_path = base_path  \n",
    "        triplets = []\n",
    "        for line in open(triplets_file_name):\n",
    "            triplets.append((line.split()[0], line.split()[1], line.split()[2])) # anchor, positive, negative\n",
    "        self.triplets = triplets\n",
    "        self.transform = transform\n",
    "        self.loader = loader\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        path1, path2, path3 = self.triplets[index]\n",
    "        img1 = self.loader(os.path.join(self.base_path, f'{path1}.jpg'))\n",
    "        img2 = self.loader(os.path.join(self.base_path, f'{path2}.jpg'))\n",
    "        img3 = self.loader(os.path.join(self.base_path, f'{path3}.jpg'))\n",
    "        if self.transform is not None:\n",
    "            img1 = self.transform(img1)\n",
    "            img2 = self.transform(img2)\n",
    "            img3 = self.transform(img3)\n",
    "\n",
    "        return img1, img2, img3\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.triplets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38209c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization: importing the packages that we will use\n",
    "import torch\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu' # Google colab offers time limited use of GPU for free\n",
    "\n",
    "################# Configuration  ######################\n",
    "IMAGE_SIZE = (354, 242) # bigger image size improves performance but makes training slower.\n",
    "\n",
    "# Training parameters \n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b63d3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset and Trasformations\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "############# Datasets and Dataloaders ################\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.ToTensor(), # The output of torchvision datasets are PILImage images of range [0, 1].\n",
    "    transforms.Resize(IMAGE_SIZE),\n",
    "    transforms.RandomHorizontalFlip(p=0.5), # we want our network to be robust over geometrical transformations that leave the image semantically invariant\n",
    "#     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)), #  We transform them to Tensors of normalized range [-1, 1].\n",
    "    # (mean, mean, mean) , (std, std, std): output[channel] = (input[channel] - mean[channel]) / std[channel]\n",
    "])\n",
    "\n",
    "transform_validate = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize(IMAGE_SIZE),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize(IMAGE_SIZE),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])\n",
    "\n",
    "path = 'C:/Users/xiaow/OneDrive/Desktop/Spring 2022/Introduction to Machine Learning/Introduction-to-Machine-Learning/Task 3/food'\n",
    "train_dataset = TripletImageLoader(path.rstrip('\\n'), 'train_triplets.txt', transform=transform_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e96a723",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset[59514]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9804534d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "loader = DataLoader(train_dataset, batch_size=1000, num_workers=0)\n",
    "data = next(iter(loader))\n",
    "len(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c826959",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = TripletImageLoader(path.rstrip('\\n'), 'test_triplets.txt', transform=transform_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80fe985",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
