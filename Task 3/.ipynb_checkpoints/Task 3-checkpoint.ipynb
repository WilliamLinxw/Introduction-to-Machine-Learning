{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cafface",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solve the imshow dead kernel problem\n",
    "import os    \n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc461e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Start loading the data\n",
    "'''\n",
    "print('================== START LOADING DATA ==================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa85839b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import os.path\n",
    "\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8218f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the training set into a 80% training set and 20% validation set\n",
    "import random\n",
    "\n",
    "def split_huge_file(file,out1,out2,percentage=0.75,seed=2022):\n",
    "    \"\"\"Splits a file in 2 given the approximate `percentage` to go in the large file.\"\"\"\n",
    "    random.seed(seed)\n",
    "    with open(file, 'r',encoding=\"utf-8\") as fin, \\\n",
    "         open(out1, 'w') as foutBig, \\\n",
    "         open(out2, 'w') as foutSmall:\n",
    "\n",
    "        for line in fin:\n",
    "            r = random.random() \n",
    "            if r < percentage:\n",
    "                foutBig.write(line)\n",
    "            else:\n",
    "                foutSmall.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a883b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:/Users/xiaow/OneDrive/Desktop/Spring 2022/Introduction to Machine Learning/Introduction-to-Machine-Learning/Task 3'\n",
    "split_huge_file(os.path.join(path, f'train_triplets.txt'), 'train_triplets_splits.txt', 'val_triplets_splits.txt', percentage=0.8, seed=2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aea5632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image loader helper function\n",
    "def default_image_loader(path):\n",
    "    return Image.open(path).convert('RGB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd6fd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "im = Image.open(r\"C:\\Users\\xiaow\\OneDrive\\Desktop\\Spring 2022\\Introduction to Machine Learning\\Introduction-to-Machine-Learning\\Task 3\\food\\00001.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb865c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9407678a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.asarray(im)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7960455c",
   "metadata": {},
   "outputs": [],
   "source": [
    "im.resize((354,242))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fe9cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletImageLoader(torch.utils.data.Dataset):\n",
    "    def __init__(self, base_path, triplets_file_name, transform=None, loader=default_image_loader):\n",
    "        \"\"\" base_path: The path contains the text file of the training triplets\n",
    "            triplets_file_name: The text file with each line containing three integers, \n",
    "            where integer i refers to the i-th image in the filenames file.  \n",
    "            Each line contains three integers (a triplet).\n",
    "            For example, the triplet \"00723 00478 02630\" denotes that the dish in image \"00723.jpg\" is more similar in taste \n",
    "            to the dish in image \"00478.jpg\" than to the dish in image \"02630.jpg\" according to a human annotator.\n",
    "         \"\"\"\n",
    "        self.base_path = base_path  \n",
    "        triplets = []\n",
    "        for line in open(triplets_file_name):\n",
    "            triplets.append((line.split()[0], line.split()[1], line.split()[2])) # anchor, positive, negative\n",
    "        self.triplets = triplets\n",
    "        self.transform = transform\n",
    "        self.loader = loader\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        path1, path2, path3 = self.triplets[index]\n",
    "        img1 = self.loader(os.path.join(self.base_path, f'{path1}.jpg'))\n",
    "        img2 = self.loader(os.path.join(self.base_path, f'{path2}.jpg'))\n",
    "        img3 = self.loader(os.path.join(self.base_path, f'{path3}.jpg'))\n",
    "        if self.transform is not None:\n",
    "            img1 = self.transform(img1)\n",
    "            img2 = self.transform(img2)\n",
    "            img3 = self.transform(img3)\n",
    "\n",
    "        return img1, img2, img3\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.triplets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38209c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization: importing the packages that we will use\n",
    "import torch\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu' # Google colab offers time limited use of GPU for free\n",
    "\n",
    "################# Configuration  ######################\n",
    "IMAGE_SIZE = (242, 354) # bigger image size improves performance but makes training slower.\n",
    "\n",
    "# Training parameters \n",
    "BATCH_SIZE = 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9974abbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b63d3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset and Trasformations\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "############# Datasets and Dataloaders ################\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.ToTensor(), # The output of torchvision datasets are PILImage images of range [0, 1].\n",
    "    transforms.Resize(IMAGE_SIZE),\n",
    "    transforms.RandomHorizontalFlip(p=0.5), # we want our network to be robust over geometrical transformations that leave the image semantically invariant\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)), #  We transform them to Tensors of normalized range [-1, 1].\n",
    "    # (mean, mean, mean) , (std, std, std): output[channel] = (input[channel] - mean[channel]) / std[channel]\n",
    "])\n",
    "\n",
    "transform_val = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize(IMAGE_SIZE),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize(IMAGE_SIZE),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])\n",
    "\n",
    "path = 'C:/Users/xiaow/OneDrive/Desktop/Spring 2022/Introduction to Machine Learning/Introduction-to-Machine-Learning/Task 3/food'\n",
    "train_dataset = TripletImageLoader(path.rstrip('\\n'), 'train_triplets_splits.txt', transform=transform_train)\n",
    "val_dataset = TripletImageLoader(path.rstrip('\\n'), 'val_triplets_splits.txt', transform=transform_val)\n",
    "test_dataset = TripletImageLoader(path.rstrip('\\n'), 'test_triplets.txt', transform=transform_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ff181f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_dataset), len(val_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66669e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9804534d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a237b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdce85ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an image\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    plt.figure()\n",
    "    plt.imshow(img.permute(1, 2, 0))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(train_loader)\n",
    "images_anchor, images_positive, images_negative = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images_anchor))\n",
    "imshow(torchvision.utils.make_grid(images_positive))\n",
    "imshow(torchvision.utils.make_grid(images_negative))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40002326",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Data loaded\n",
    "'''\n",
    "print('================== DATA LOADED ==================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87028c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Start constructing the network\n",
    "'''\n",
    "print('================== START CONSTRUCTING NETWORK ==================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae256a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torch.utils.data\n",
    "\n",
    "#########################NET##############################\n",
    "\n",
    "#The backbone for the CNNS with shared weights\n",
    "def backbone(**kwargs):\n",
    "    \"\"\"\n",
    "    Construct a ResNet-101 model.\n",
    "    Returns:\n",
    "        Embeddingnet(model): The CNN with the specified model as its backbone is instantiated\n",
    "    \"\"\"\n",
    "    #model = torch.hub.load('pytorch/vision:v1.7.1', 'resnet101', pretrained=True)\n",
    "    model = models.resnet18(pretrained=True)\n",
    "    #model = models.resnet34(pretrained=True)\n",
    "    #model = models.vgg11_bn()\n",
    "    #model = torch.hub.load('pytorch/vision:v0.8.2', 'alexnet', pretrained=True)\n",
    "    #model = models.alexnet(pretrained=True)            #used in the paper\n",
    "    #print('Layers',model.children)\n",
    "    #model = models.resnet50(pretrained=True)\n",
    "    #model = models.inception_v3(pretrained=True)\n",
    "    #model = torchvision.models.resnet.ResNet(\n",
    "        #torchvision.models.resnet.BasicBlock, [2, 1, 1, 1])\n",
    "\n",
    "    return EmbeddingNet(model)\n",
    "\n",
    "#The overall network consisting of three embedding nets with shared weights\n",
    "class TripletNet(nn.Module):\n",
    "    \"\"\"Triplet Network.\"\"\"\n",
    "\n",
    "    def __init__(self, embeddingnet):\n",
    "        \"\"\"Triplet Network Builder.\"\"\"\n",
    "        super(TripletNet, self).__init__()\n",
    "        self.embeddingnet = embeddingnet\n",
    "        #print(self.embeddingnet.children())\n",
    "\n",
    "    def forward(self, a, p, n):\n",
    "        \"\"\"Forward pass.\"\"\"\n",
    "        # anchor\n",
    "        embedded_a = self.embeddingnet(a)\n",
    "\n",
    "        # positive examples\n",
    "        embedded_p = self.embeddingnet(p)\n",
    "\n",
    "        # negative examples\n",
    "        embedded_n = self.embeddingnet(n)\n",
    "\n",
    "        return embedded_a, embedded_p, embedded_n\n",
    "\n",
    "#The CNN used by Triplet Net with 'model' as its backbone and a final fully connected Layer\n",
    "class EmbeddingNet(nn.Module):\n",
    "    \"\"\"EmbeddingNet using the specified model in backbone().\"\"\"\n",
    "\n",
    "    def __init__(self, resnet):\n",
    "        \"\"\"Initialize EmbeddingNet model.\"\"\"\n",
    "        super(EmbeddingNet, self).__init__()\n",
    "        # Everything excluding the last linear layer\n",
    "        self.features = nn.Sequential(*list(resnet.children())[:-1])\n",
    "        num_ftrs =  resnet.fc.in_features\n",
    "        self.fc1 = nn.Linear(num_ftrs, 1024)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass of EmbeddingNet.\"\"\"\n",
    "        out = self.features(x)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc1(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7605800f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a triplet net\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torch.utils.data\n",
    "\n",
    "#########################NET##############################\n",
    "\n",
    "#The backbone for the CNNS with shared weights\n",
    "def FeatureExtractNET(**kwargs):\n",
    "    \"\"\"\n",
    "    Construct a ResNet-101 model.\n",
    "    Returns: The CNN for feature extraction with a fully connected layer\n",
    "    \"\"\"\n",
    "    model = models.resnet18(pretrained=True)\n",
    "\n",
    "    return EmbeddingNet(model)\n",
    "\n",
    "#The CNN used by Triplet Net with 'model' as its backbone and a final fully connected Layer\n",
    "class EmbeddingNet(nn.Module):\n",
    "    \"\"\"EmbeddingNet using the specified model in backbone().\"\"\"\n",
    "\n",
    "    def __init__(self, resnet):\n",
    "        \"\"\"Initialize EmbeddingNet model.\"\"\"\n",
    "        super(EmbeddingNet, self).__init__()\n",
    "        # Everything excluding the last linear layer\n",
    "        self.features = nn.Sequential(*list(resnet.children())[:-1])\n",
    "        num_ftrs =  resnet.fc.in_features\n",
    "        self.fc1 = nn.Linear(num_ftrs, 1024)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass of EmbeddingNet.\"\"\"\n",
    "        out = self.features(x)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc1(out)\n",
    "        return out\n",
    "    \n",
    "#The overall network consisting of three embedding nets with shared weights\n",
    "class TripletNet(nn.Module):\n",
    "    \"\"\"Triplet Network.\"\"\"\n",
    "\n",
    "    def __init__(self, embeddingnet):\n",
    "        \"\"\"Triplet Network Builder.\"\"\"\n",
    "        super(TripletNet, self).__init__()\n",
    "        self.embeddingnet = embeddingnet\n",
    "\n",
    "    def forward(self, a, p, n):\n",
    "        \"\"\"Forward pass.\"\"\"\n",
    "        # anchor\n",
    "        embedded_a = self.embeddingnet(a)\n",
    "\n",
    "        # positive examples\n",
    "        embedded_p = self.embeddingnet(p)\n",
    "\n",
    "        # negative examples\n",
    "        embedded_n = self.embeddingnet(n)\n",
    "\n",
    "        return embedded_a, embedded_p, embedded_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7843631c",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = TripletNet(backbone())\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3626cfdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(train_loader))\n",
    "net(batch[0],batch[1],batch[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71be7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hiddenlayer as hl\n",
    "\n",
    "transforms = [hl.transforms.Prune('Constant')] # Removes Constant nodes from graph.\n",
    "\n",
    "graph = hl.build_graph(net, (batch[0], batch[1], batch[2]), transforms=transforms)\n",
    "graph.theme = hl.graph.THEMES['blue'].copy()\n",
    "graph.save('rnn_hiddenlayer_1', format='png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa4121e",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.TripletMarginLoss(margin=5.0, p=2)\n",
    "\n",
    "optimizer = torch.optim.SGD(net.parameters(),\n",
    "                            lr=0.0005,\n",
    "                            momentum=0.9,\n",
    "                            weight_decay=2e-3,#The value used in the paper is 1e-3\n",
    "                            nesterov=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239e50ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "for epoch in range(1):\n",
    "\n",
    "        running_loss = 0.0\n",
    "        loss_train = 0.0\n",
    "        for batch_idx, (data1, data2, data3) in enumerate(train_loader):\n",
    "\n",
    "#             if is_gpu:\n",
    "#                 data1, data2, data3 = data1.cuda(), data2.cuda(), data3.cuda()\n",
    "\n",
    "            # wrap in torch.autograd.Variable\n",
    "            data1, data2, data3 = Variable(\n",
    "                data1), Variable(data2), Variable(data3)\n",
    "            print('anchor', data1.size())\n",
    "            print('positive', data2.size())\n",
    "            print('negative', data3.size())\n",
    "\n",
    "            # compute output and loss\n",
    "            embedded_a, embedded_p, embedded_n = net(data1, data2, data3)\n",
    "            loss = criterion(embedded_a, embedded_p, embedded_n)\n",
    "            print(loss)\n",
    "\n",
    "            # compute gradient and do optimizer step\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print the loss\n",
    "            running_loss += loss.data\n",
    "\n",
    "#             loss_train_cls = torch.sum(\n",
    "#                 1 * (criterion_val(embedded_a, embedded_p,\n",
    "#                                    embedded_n) > 0)) / train_batch_size  # CHANGED, MAY NEED TO REVERT BACK\n",
    "\n",
    "#             loss_train += loss_train_cls.data\n",
    "\n",
    "            if batch_idx % 30 == 0:\n",
    "                print(\"mini Batch Loss: {}\".format(loss.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3dca38",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Network constructed\n",
    "'''\n",
    "print('================== NETWORK CONSTRUCTED ==================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad7dce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function and Optimizer\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.TripletMarginLoss(margin=5, p=2, reduction='mean')\n",
    "optimizer = optim.Adam(net.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e25fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, criterion, optimizer, epochs, trainloader):\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0\n",
    "        for batch_idx, (data0, data1, data2) in enumerate(trainloader):\n",
    "            anchor, positive, negative = data0, data1, data2\n",
    "#             anchor = Variable(anchor)\n",
    "#             positive = Variable(positive)\n",
    "#             negative = Variable(negative)\n",
    "            print('anchor', anchor.size())\n",
    "            print('positive', positive.size())\n",
    "            print('negative', negative.size())\n",
    "            \n",
    "            # Calculate the output of three networks\n",
    "            embedded_a, embedded_p, embedded_n = model(anchor, positive, negative)\n",
    "            \n",
    "            # Calculate the loss\n",
    "            loss = criterion(embedded_a, embedded_p, embedded_n)\n",
    "            print(loss)\n",
    "            \n",
    "            # Zero the gradient\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Back prop and update\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "        print(f'[{epoch + 1}] average loss per epoch: {running_loss / len(train_loader):.3f}')\n",
    "        # save checkpoint of model\n",
    "        if epoch % 5 == 0 and epoch > 0:\n",
    "            save_path = f'model_epoch_{epoch}.pt'\n",
    "            torch.save({'epoch': epoch, 'model_state_dict': model.state_dict(), 'optimizer_state_dict': optim.state_dict()}, save_path)\n",
    "        print(f'Saved model checkpoint to {save_path}')\n",
    "        \n",
    "    print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7f8cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(net, criterion, optimizer, 1, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ed9003",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
